{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import re\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_csv('DataDict.csv')\n",
    "df = pd.read_csv('WDI_CSV_2024_06_28/WDICSV.csv')\n",
    "country = pd.read_excel('WDI_Country.xlsx')\n",
    "\n",
    "gdp = df[df['Indicator Code'].isin(['NY.GDP.MKTP.CD'])]\n",
    "gdp = gdp.drop(['Country Code','Indicator Name','Indicator Code'],axis=1)\n",
    "gdp = gdp.melt(id_vars= [\"Country Name\"],var_name=\"Year\",value_name=\"gdp\")\n",
    "\n",
    "imp = df[df['Indicator Code'].isin(['NE.IMP.GNFS.CD'])]\n",
    "imp = imp.drop(['Country Code','Indicator Name','Indicator Code'],axis=1)\n",
    "imp = imp.melt(id_vars= [\"Country Name\"],var_name=\"Year\",value_name=\"imp\")\n",
    "\n",
    "gdp_cn = df[df['Indicator Code'].isin(['NY.GDP.MKTP.CN'])]\n",
    "gdp_cn = gdp_cn.drop(['Country Code','Indicator Name','Indicator Code'],axis=1)\n",
    "gdp_cn = gdp_cn.melt(id_vars= [\"Country Name\"],var_name=\"Year\",value_name=\"gdp_cn\")\n",
    "\n",
    "df = df[df['Indicator Code'].isin(dd['Code in Source'])]\n",
    "vlist = []\n",
    "years = []\n",
    "for i in dd.index:\n",
    "    v = dd.loc[i,'Variable']\n",
    "    code = dd.loc[i,'Code in Source']\n",
    "    f = dd.loc[i,'Formula']\n",
    "    if dd.isnull().loc[i,'Decimal Places']:\n",
    "        d = dd.loc[i,'Decimal Places']\n",
    "    else:\n",
    "        d = int(dd.loc[i,'Decimal Places'])\n",
    "    dt = df[df['Indicator Code'].isin([code])]\n",
    "    dt = dt.drop(['Country Code','Indicator Name','Indicator Code'],axis=1)\n",
    "    dt = dt.melt(id_vars= [\"Country Name\"],var_name=\"Year\",value_name=\"val\")\n",
    "    if dd.isnull().loc[i,'Formula']:\n",
    "        dt = dt\n",
    "    elif f == \"%'NE.IMP.GNFS.CD'\":\n",
    "        dt = dt.merge(imp, on = ['Country Name', 'Year'], how = 'left')\n",
    "        dt['cval'] = dt['val']/dt['imp']*100\n",
    "        dt = dt.drop(['val'], axis = 1)\n",
    "        dt = dt.rename(columns={'cval':'val'})\n",
    "    elif f ==\"%'NY.GDP.MKTP.CN'\":\n",
    "        dt = dt.merge(gdp_cn, on = ['Country Name', 'Year'], how = 'left')\n",
    "        dt['cval'] = dt['val']/dt['gdp_cn']*100\n",
    "        dt = dt.drop(['val'], axis = 1)\n",
    "        dt = dt.rename(columns={'cval':'val'})\n",
    "    elif f == '/1000000000':\n",
    "        dt.val = dt.val/1000000000\n",
    "    elif f == '/1000000':\n",
    "        dt.val = dt.val/1000000\n",
    "    else:\n",
    "        dt = dt.merge(gdp, on = ['Country Name', 'Year'], how = 'left')\n",
    "        dt['cval'] = dt['val']/dt['gdp']*100\n",
    "        dt = dt.drop(['val'], axis = 1)\n",
    "        dt = dt.rename(columns={'cval':'val'})\n",
    "    if dd.isnull().loc[i,'Decimal Places']:\n",
    "        dt = dt\n",
    "    else:\n",
    "        dt.val = round(dt.val, d)\n",
    "\n",
    "    n = 'Country Name'\n",
    "    y = 'Year'\n",
    "    first_last = dt.sort_values([n,y]).groupby(dt[n])['val'] \\\n",
    "            .agg(['first', 'last']).reset_index()\n",
    "    first_last = first_last.rename(columns={\"first\": \"Earliest\", \"last\": \"MostRecent\"})\n",
    "    dt.Year = dt.Year.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "    dt = dt.pivot_table(index = n,\n",
    "                    columns= y,\n",
    "                    values = 'val').reset_index()\n",
    "    dt = dt.merge(first_last,\n",
    "                on = n,\n",
    "                how = 'left')\n",
    "    dt = country.merge(dt,\n",
    "                    on = n,\n",
    "                    how = 'left')\n",
    "    dt = dt.drop(columns= n)\n",
    "    # dt.to_csv(f'IFs Import/{v}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools as mit\n",
    "def find_ranges(iterable):\n",
    "    \"\"\"Yield range of consecutive numbers.\"\"\"\n",
    "    for group in mit.consecutive_groups(iterable):\n",
    "        group = list(group)\n",
    "        if len(group) == 1:\n",
    "            yield group[0]\n",
    "        else:\n",
    "            yield group[0], group[-1]\n",
    "\n",
    "def side_values(num_list):\n",
    "    results_list = sorted(num_list)\n",
    "    results = (str(results_list[0]) + \"-\" + str(results_list[-1]))\n",
    "    return results\n",
    "\n",
    "# dd = pd.read_excel('DataDict.xlsx', \n",
    "#                 #    sheet_name='All_files_Import'\n",
    "#                    )\n",
    "dd = pd.read_csv('DataDict.csv')\n",
    "\n",
    "tblist = []\n",
    "years = []\n",
    "duration = []\n",
    "realduration = []\n",
    "for tb in dd.Table:\n",
    "    v = tb.replace(\"Series\",\"\")\n",
    "    #v = v.replace(\"Rev23\",\"\")\n",
    "    # print(v)\n",
    "    dt = pd.read_csv(f\"IFs Import/{v}.csv\")\n",
    "    dt = dt.drop(columns=['Earliest','MostRecent'])\n",
    "    dt = dt.melt(id_vars= [\"Country\",\"FIPS_CODE\"],var_name=\"Year\",value_name=\"val\")\n",
    "    dt.Year = dt.Year.apply(pd.to_numeric, errors='coerce')\n",
    "    tblist.append(v)\n",
    "    ymax = dt.Year.max()\n",
    "    ymin = dt.Year.min()\n",
    "    # years.append(str(ymin)+\"-\"+str(ymax))\n",
    "    year1 = []\n",
    "    for l in list(find_ranges(dt.Year.unique())):\n",
    "        try:\n",
    "            somelist = side_values(l)\n",
    "            year1.append(somelist)\n",
    "            # print(somelist)\n",
    "        except:\n",
    "            year1.append(str(l))\n",
    "            # print(l)\n",
    "    years.append(year1)\n",
    "    duration.append(ymax-ymin+1)\n",
    "    dt = dt.pivot(index=[\"Country\",\"FIPS_CODE\"],\n",
    "                  columns='Year',\n",
    "                  values='val'\n",
    "                  )\n",
    "    realduration.append(dt.shape[1])\n",
    "df = pd.DataFrame({'Variable': tblist,\n",
    "              'Years': years,\n",
    "              'Duration': duration,\n",
    "              \"Realcolnum\": realduration\n",
    "             })\n",
    "df.Years = df['Years'].str.join(', ')\n",
    "\n",
    "df\n",
    "df.to_excel('Years.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_csv('DataDict.csv')\n",
    "conn = sqlite3.connect('IFsDataImport.db')\n",
    "cursor = conn.cursor()\n",
    "#\n",
    "for tb in dd.Table:\n",
    "    v = tb.replace(\"Series\",\"\")\n",
    "    #v = v.replace(\"Rev23\",\"\")\n",
    "    print(v)\n",
    "    dt = pd.read_csv(f\"IFs Import/{v}.csv\")\n",
    "    sql_drop_table = f\"DROP TABLE IF EXISTS [{tb}];\"\n",
    "    sql_create_table = f\"CREATE TABLE [{tb}] (Country VARCHAR (255), FIPS_CODE VARCHAR (255), \"\n",
    "    for c in dt.columns[2:]:\n",
    "        sql_create_table += f\"[{c}] DOUBLE(53),\"\n",
    "    sql_create_table = sql_create_table[:-1] + \");\"\n",
    "    cursor.execute(sql_drop_table)\n",
    "    cursor.execute(sql_create_table)\n",
    "    dt.to_sql(name=f'{tb}', con=conn, if_exists=\"append\", index=False)\n",
    "    conn.commit()\n",
    "#dd_update.to_sql(name=f'DataDict', con=conn, if_exists=\"replace\", index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ifshist_path_old = \n",
    "conn_wdi = sqlite3.connect(\"IFsDataImport.db\")\n",
    "cursor_wdi = conn_wdi.cursor()\n",
    "dd_wdi = pd.read_sql_query(\"SELECT * FROM [DataDict]\", conn_wdi)\n",
    "##\n",
    "conn_ifs_old =  sqlite3.connect(r\"C:\\Users\\Public\\IFs\\DATA\\IFsHistSeries.db\")\n",
    "for tb in dd_wdi[\"Table\"]:\n",
    "    df_ifs = pd.read_sql_query(f\"SELECT * FROM [{tb}]\", conn_ifs_old)\n",
    "    df_wdi = pd.read_sql_query(f\"SELECT * FROM [{tb}]\",conn_wdi)\n",
    "    df_ifs = df_ifs.drop(columns=[\"Earliest\", \"MostRecent\"]).sort_values(by=[\"Country\"]).reset_index(drop=True)\n",
    "    df_wdi = df_wdi.drop(columns=[\"Earliest\", \"MostRecent\"]).sort_values(by=[\"Country\"]).reset_index(drop=True)\n",
    "    df_wdi_fill = df_wdi.copy()\n",
    "   # fill in historical values\n",
    "    col_emp = []\n",
    "    for c in df_wdi.columns[2:]:\n",
    "        if df_wdi[c].dropna().empty:\n",
    "            if c in df_ifs.columns and not df_ifs[c].empty:\n",
    "                df_wdi_fill[c] = df_ifs[c]\n",
    "            else:\n",
    "                col_emp.append(c)\n",
    "        else:\n",
    "            break \n",
    "    # add empty year columns to drop from the latest time\n",
    "    col_rev = list(df_wdi.columns)\n",
    "    col_rev.reverse()\n",
    "    for c in col_rev:\n",
    "        if df_wdi[c].dropna().empty:\n",
    "            col_emp.append(c)\n",
    "        else:\n",
    "            break\n",
    "    # fill in missing countries\n",
    "    country_emp = []\n",
    "    for c in df_wdi.Country:\n",
    "        if df_wdi[df_wdi.Country==c].dropna(axis=1).shape[1]==2:\n",
    "            df_wdi_fill = df_wdi_fill.loc[df_wdi_fill.Country!= c]\n",
    "            country_emp.append(c)\n",
    "    df_wdi_fill = pd.concat([df_wdi_fill,df_ifs[df_ifs.Country.isin(country_emp)]])\n",
    "    #\n",
    "    df_wdi_fill = df_wdi_fill.drop(columns=col_emp)\n",
    "    # Add most recent & earliest columns\n",
    "    df_wdi_fill = df_wdi_fill.sort_values(by=[\"Country\"]).reset_index(drop=True)\n",
    "    df = df_wdi_fill.copy(True)\n",
    "    for c in df.columns[2:]:\n",
    "        if df[c].dtypes == \"O\":\n",
    "            df[c] = df[c].astype(float)\n",
    "    Ear=[]\n",
    "    Rec=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        line=df.iloc[i,2:]\n",
    "        line.dropna(inplace=True)\n",
    "        if not line.empty:\n",
    "            Ear.append(line.values[0])\n",
    "            Rec.append(line.values[-1])\n",
    "        else:\n",
    "            Ear.append(np.NaN)\n",
    "            Rec.append(np.NaN)\n",
    "    df[\"Earliest\"]=Ear\n",
    "    df[\"MostRecent\"]=Rec\n",
    "    sql_drop_table = f\"DROP TABLE IF EXISTS [{tb}];\"\n",
    "    sql_create_table = f\"CREATE TABLE [{tb}] (Country VARCHAR (255), FIPS_CODE VARCHAR (255), \"       \n",
    "    for c in df.columns[2:]:\n",
    "        sql_create_table += f\"[{c}] DOUBLE(53),\"\n",
    "    sql_create_table = sql_create_table[:-1] + \");\"\n",
    "    cursor_wdi.execute(sql_drop_table)\n",
    "    cursor_wdi.execute(sql_create_table)\n",
    "    df.to_sql(name=f'{tb}', con=conn_wdi, if_exists=\"append\", index=False)\n",
    "conn_wdi.commit()\n",
    "conn_wdi.close()\n",
    "conn_ifs_old.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
